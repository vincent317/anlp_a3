{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load texts from C4 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "def load_json_gz(filename):\n",
    "    with gzip.open(filename, 'r') as f:\n",
    "        i = 0\n",
    "        ret = []\n",
    "        for json_line in f:\n",
    "            if i == 10000:\n",
    "                return ret\n",
    "            data = json.loads(json_line)\n",
    "            text = data['text']\n",
    "            if len(text) > 2000:\n",
    "                ret.append(text)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 10000 strings from C4 dataset: https://huggingface.co/datasets/allenai/c4/tree/main/en\n",
    "strings = load_json_gz('c4-train.00000-of-01024.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mamba_out/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_task(batch_size=64, batches=10, model=None, tokenizer=None, token_max_len=25, shuffle=False):\n",
    "    string_idx = 0\n",
    "    success_copies = 0\n",
    "    for _ in tqdm(range(batches)):\n",
    "        cur_batch = []\n",
    "        for count in range(batch_size):\n",
    "            cur_batch.append(strings[count + string_idx])\n",
    "        input_ids = tokenizer(cur_batch, return_tensors=\"pt\", truncation=True, max_length=token_max_len).to(device)[\"input_ids\"]\n",
    "        if shuffle:\n",
    "            col_perm = torch.randperm(input_ids.size(1))\n",
    "            input_ids = input_ids[:, col_perm]\n",
    "        input_ids = torch.cat([input_ids, input_ids], dim=1)\n",
    "        input_ids = torch.cat([input_ids, input_ids[:, 0:1]], dim=1)\n",
    "        output_ids = model.generate(input_ids, max_new_tokens = token_max_len-1)\n",
    "        for count in range(batch_size):\n",
    "            gold_token_len = (input_ids.shape[1]-1) // 2\n",
    "            if torch.equal(input_ids[count][:gold_token_len], output_ids[count][gold_token_len*2:]):\n",
    "                success_copies += 1\n",
    "        string_idx += batch_size\n",
    "    return success_copies / (batch_size * batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pythia Copying (with or without shuffle) Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Pythia 410m results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoXForCausalLM\n",
    "pythia_410m_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  \"EleutherAI/pythia-410m\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-410m/step3000\",\n",
    ")\n",
    "pythia_410m_model.to(device)\n",
    "pythia_410m_tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"EleutherAI/pythia-410m\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-410m/step3000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(copy_task(model=pythia_410m_model, tokenizer=pythia_410m_tokenizer, token_max_len=25))\n",
    "# print(copy_task(model=pythia_410m_model, tokenizer=pythia_410m_tokenizer, token_max_len=50))\n",
    "# print(copy_task(model=pythia_410m_model, tokenizer=pythia_410m_tokenizer, token_max_len=100))\n",
    "# print(copy_task(batch_size=32, batches=20, model=pythia_410m_model, tokenizer=pythia_410m_tokenizer, token_max_len=150))\n",
    "# print(copy_task(batch_size=32, batches=20, model=pythia_410m_model, tokenizer=pythia_410m_tokenizer, token_max_len=200))\n",
    "# print(copy_task(batch_size=32, batches=20, model=pythia_410m_model, tokenizer=pythia_410m_tokenizer, token_max_len=250))\n",
    "\n",
    "# 50, 0.896\n",
    "# 100, 0.7625\n",
    "# 200, 0.5562\n",
    "# 300, 0.364\n",
    "# 400, 0.214\n",
    "# 500, 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Pythia 1.4B results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ValueError('Queue is full! Please try again.')\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoXForCausalLM\n",
    "pythia_1_4b_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  \"EleutherAI/pythia-1.4b\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-1.4b/step3000\",\n",
    ")\n",
    "pythia_1_4b_model.to(device)\n",
    "pythia_1_4b_tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"EleutherAI/pythia-1.4b\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-1.4b/step3000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(copy_task(model=pythia_1_4b_model, tokenizer=pythia_1_4b_tokenizer, token_max_len=25))\n",
    "# print(copy_task(batch_size=32, batches=20, model=pythia_1_4b_model, tokenizer=pythia_1_4b_tokenizer, token_max_len=50))\n",
    "# print(copy_task(batch_size=32, batches=20, model=pythia_1_4b_model, tokenizer=pythia_1_4b_tokenizer, token_max_len=100))\n",
    "# print(copy_task(batch_size=16, batches=40, model=pythia_1_4b_model, tokenizer=pythia_1_4b_tokenizer, token_max_len=150))\n",
    "# print(copy_task(batch_size=16, batches=40, model=pythia_1_4b_model, tokenizer=pythia_1_4b_tokenizer, token_max_len=200))\n",
    "print(copy_task(batch_size=8, batches=80, model=pythia_1_4b_model, tokenizer=pythia_1_4b_tokenizer, token_max_len=250))\n",
    "\n",
    "# pythia-1.4b\n",
    "# 50, 0.8109\n",
    "# 100, 0.74375\n",
    "# 200, 0.7375\n",
    "# 300, 0.665625\n",
    "# 400, 0.575\n",
    "# 500, 0.484375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Pythia 2.8B results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ValueError('Queue is full! Please try again.')\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoXForCausalLM\n",
    "pythia_2_8b_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  \"EleutherAI/pythia-2.8b\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-2.8b/step3000\",\n",
    ")\n",
    "pythia_2_8b_model.to(device)\n",
    "pythia_2_8b_tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"EleutherAI/pythia-2.8b\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-2.8b/step3000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/160 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  1%|          | 1/160 [00:19<50:44, 19.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  1%|▏         | 2/160 [00:35<46:48, 17.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  2%|▏         | 3/160 [00:52<45:17, 17.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  2%|▎         | 4/160 [01:09<44:25, 17.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  3%|▎         | 5/160 [01:26<43:50, 16.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  4%|▍         | 6/160 [01:43<43:23, 16.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  4%|▍         | 7/160 [01:59<43:00, 16.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  5%|▌         | 8/160 [02:16<42:40, 16.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  6%|▌         | 9/160 [02:33<42:20, 16.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  6%|▋         | 10/160 [02:50<42:02, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  7%|▋         | 11/160 [03:06<41:43, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  8%|▊         | 12/160 [03:23<41:26, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  8%|▊         | 13/160 [03:40<41:09, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  9%|▉         | 14/160 [03:57<40:52, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  9%|▉         | 15/160 [04:14<40:35, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 10%|█         | 16/160 [04:30<40:18, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 11%|█         | 17/160 [04:47<40:01, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 11%|█▏        | 18/160 [05:04<39:44, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 12%|█▏        | 19/160 [05:21<39:27, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 12%|█▎        | 20/160 [05:38<39:11, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 13%|█▎        | 21/160 [05:54<38:55, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 14%|█▍        | 22/160 [06:11<38:38, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 14%|█▍        | 23/160 [06:28<38:20, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 15%|█▌        | 24/160 [06:45<38:03, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 16%|█▌        | 25/160 [07:02<37:46, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 16%|█▋        | 26/160 [07:18<37:29, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 17%|█▋        | 27/160 [07:35<37:12, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 18%|█▊        | 28/160 [07:52<36:55, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 18%|█▊        | 29/160 [08:09<36:39, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 19%|█▉        | 30/160 [08:25<36:23, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 19%|█▉        | 31/160 [08:42<36:06, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 20%|██        | 32/160 [08:59<35:50, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 21%|██        | 33/160 [09:16<35:33, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 21%|██▏       | 34/160 [09:33<35:16, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 22%|██▏       | 35/160 [09:49<34:59, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 22%|██▎       | 36/160 [10:06<34:42, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 23%|██▎       | 37/160 [10:23<34:25, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 24%|██▍       | 38/160 [10:40<34:08, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 24%|██▍       | 39/160 [10:57<33:51, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 25%|██▌       | 40/160 [11:13<33:34, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 26%|██▌       | 41/160 [11:30<33:17, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 26%|██▋       | 42/160 [11:47<33:01, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 27%|██▋       | 43/160 [12:04<32:44, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 28%|██▊       | 44/160 [12:21<32:29, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 28%|██▊       | 45/160 [12:37<32:12, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 29%|██▉       | 46/160 [12:54<31:56, 16.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 29%|██▉       | 47/160 [13:11<31:39, 16.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 30%|███       | 48/160 [13:28<31:21, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 31%|███       | 49/160 [13:45<31:04, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 31%|███▏      | 50/160 [14:01<30:47, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 32%|███▏      | 51/160 [14:18<30:30, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 32%|███▎      | 52/160 [14:35<30:13, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 33%|███▎      | 53/160 [14:52<29:56, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 34%|███▍      | 54/160 [15:09<29:39, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 34%|███▍      | 55/160 [15:25<29:23, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 35%|███▌      | 56/160 [15:42<29:06, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 36%|███▌      | 57/160 [15:59<28:49, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 36%|███▋      | 58/160 [16:16<28:32, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 37%|███▋      | 59/160 [16:32<28:15, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 38%|███▊      | 60/160 [16:49<27:58, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 38%|███▊      | 61/160 [17:06<27:41, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 39%|███▉      | 62/160 [17:23<27:24, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 39%|███▉      | 63/160 [17:40<27:08, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 40%|████      | 64/160 [17:56<26:51, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 41%|████      | 65/160 [18:13<26:34, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 41%|████▏     | 66/160 [18:30<26:19, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 42%|████▏     | 67/160 [18:47<26:02, 16.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 42%|████▎     | 68/160 [19:04<25:46, 16.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 43%|████▎     | 69/160 [19:20<25:29, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 44%|████▍     | 70/160 [19:37<25:12, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 44%|████▍     | 71/160 [19:54<24:55, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 45%|████▌     | 72/160 [20:11<24:38, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 46%|████▌     | 73/160 [20:28<24:21, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 46%|████▋     | 74/160 [20:44<24:04, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 47%|████▋     | 75/160 [21:01<23:47, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 48%|████▊     | 76/160 [21:18<23:30, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 48%|████▊     | 77/160 [21:35<23:14, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 49%|████▉     | 78/160 [21:52<22:57, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 49%|████▉     | 79/160 [22:08<22:40, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 50%|█████     | 80/160 [22:25<22:23, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 51%|█████     | 81/160 [22:42<22:06, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 51%|█████▏    | 82/160 [22:59<21:49, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 52%|█████▏    | 83/160 [23:16<21:32, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 52%|█████▎    | 84/160 [23:32<21:15, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 53%|█████▎    | 85/160 [23:49<20:58, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 54%|█████▍    | 86/160 [24:06<20:41, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 54%|█████▍    | 87/160 [24:23<20:25, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 55%|█████▌    | 88/160 [24:39<20:08, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 56%|█████▌    | 89/160 [24:56<19:51, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 56%|█████▋    | 90/160 [25:13<19:34, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 57%|█████▋    | 91/160 [25:30<19:18, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 57%|█████▊    | 92/160 [25:47<19:01, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 58%|█████▊    | 93/160 [26:03<18:44, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 59%|█████▉    | 94/160 [26:20<18:28, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 59%|█████▉    | 95/160 [26:37<18:11, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 60%|██████    | 96/160 [26:54<17:54, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 61%|██████    | 97/160 [27:11<17:38, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 61%|██████▏   | 98/160 [27:27<17:21, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 62%|██████▏   | 99/160 [27:44<17:04, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 62%|██████▎   | 100/160 [28:01<16:47, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 63%|██████▎   | 101/160 [28:18<16:30, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 64%|██████▍   | 102/160 [28:34<16:13, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 64%|██████▍   | 103/160 [28:51<15:56, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 65%|██████▌   | 104/160 [29:08<15:39, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 66%|██████▌   | 105/160 [29:25<15:23, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 66%|██████▋   | 106/160 [29:42<15:06, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 67%|██████▋   | 107/160 [29:58<14:49, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 68%|██████▊   | 108/160 [30:15<14:33, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 68%|██████▊   | 109/160 [30:32<14:16, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 69%|██████▉   | 110/160 [30:49<13:59, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 69%|██████▉   | 111/160 [31:06<13:42, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 70%|███████   | 112/160 [31:22<13:26, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 71%|███████   | 113/160 [31:39<13:09, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 71%|███████▏  | 114/160 [31:56<12:52, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 72%|███████▏  | 115/160 [32:13<12:35, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 72%|███████▎  | 116/160 [32:30<12:18, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 73%|███████▎  | 117/160 [32:46<12:02, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 74%|███████▍  | 118/160 [33:03<11:45, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 74%|███████▍  | 119/160 [33:20<11:28, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 75%|███████▌  | 120/160 [33:37<11:11, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 76%|███████▌  | 121/160 [33:53<10:54, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 76%|███████▋  | 122/160 [34:10<10:37, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 77%|███████▋  | 123/160 [34:27<10:20, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 78%|███████▊  | 124/160 [34:44<10:04, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 78%|███████▊  | 125/160 [35:01<09:47, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 79%|███████▉  | 126/160 [35:17<09:30, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 79%|███████▉  | 127/160 [35:34<09:13, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 80%|████████  | 128/160 [35:51<08:57, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 81%|████████  | 129/160 [36:08<08:40, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 81%|████████▏ | 130/160 [36:25<08:23, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 82%|████████▏ | 131/160 [36:41<08:06, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 82%|████████▎ | 132/160 [36:58<07:49, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 83%|████████▎ | 133/160 [37:15<07:33, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 84%|████████▍ | 134/160 [37:32<07:16, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 84%|████████▍ | 135/160 [37:48<06:59, 16.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 85%|████████▌ | 136/160 [38:05<06:42, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 86%|████████▌ | 137/160 [38:22<06:26, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 86%|████████▋ | 138/160 [38:39<06:09, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 87%|████████▋ | 139/160 [38:56<05:52, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 88%|████████▊ | 140/160 [39:12<05:35, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 88%|████████▊ | 141/160 [39:29<05:18, 16.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 89%|████████▉ | 142/160 [39:46<05:02, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 89%|████████▉ | 143/160 [40:03<04:45, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 90%|█████████ | 144/160 [40:20<04:28, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 91%|█████████ | 145/160 [40:36<04:12, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 91%|█████████▏| 146/160 [40:53<03:55, 16.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 92%|█████████▏| 147/160 [41:10<03:38, 16.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 92%|█████████▎| 148/160 [41:27<03:21, 16.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 93%|█████████▎| 149/160 [41:44<03:04, 16.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 94%|█████████▍| 150/160 [42:01<02:48, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 94%|█████████▍| 151/160 [42:17<02:31, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 95%|█████████▌| 152/160 [42:34<02:14, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 96%|█████████▌| 153/160 [42:51<01:57, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 96%|█████████▋| 154/160 [43:08<01:40, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 97%|█████████▋| 155/160 [43:25<01:24, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 98%|█████████▊| 156/160 [43:41<01:07, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 98%|█████████▊| 157/160 [43:58<00:50, 16.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 99%|█████████▉| 158/160 [44:15<00:33, 16.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 99%|█████████▉| 159/160 [44:32<00:16, 16.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "100%|██████████| 160/160 [44:49<00:00, 16.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print(copy_task(batch_size=32, batches=20, model=pythia_2_8b_model, tokenizer=pythia_2_8b_tokenizer, token_max_len=25))\n",
    "# print(copy_task(batch_size=16, batches=40, model=pythia_2_8b_model, tokenizer=pythia_2_8b_tokenizer, token_max_len=50))\n",
    "# print(copy_task(batch_size=8, batches=80, model=pythia_2_8b_model, tokenizer=pythia_2_8b_tokenizer, token_max_len=100))\n",
    "# print(copy_task(batch_size=4, batches=160, model=pythia_2_8b_model, tokenizer=pythia_2_8b_tokenizer, token_max_len=150))\n",
    "# print(copy_task(batch_size=4, batches=160, model=pythia_2_8b_model, tokenizer=pythia_2_8b_tokenizer, token_max_len=200))\n",
    "print(copy_task(batch_size=2, batches=160, model=pythia_2_8b_model, tokenizer=pythia_2_8b_tokenizer, token_max_len=250)) # Too long to run full 640 samples\n",
    "\n",
    "# pythia-2.8B\n",
    "# 50, 0.8296875\n",
    "# 100, 0.796875\n",
    "# 200, 0.7390625\n",
    "# 300, 0.6796875\n",
    "# 400, 0.6171875\n",
    "# 500, 0.525"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mamba Copying (with or without shuffle) Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Mamba-370m results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_370m_tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-370m-hf\")\n",
    "mamba_370m_model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-370m-hf\")\n",
    "mamba_370m_model.to(device)\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=25))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=50))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=100))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=150))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=200))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=250))\n",
    "# 0.8578125, 00:21\n",
    "# 0.703125, 00:36\n",
    "# 0.509375, 01:10\n",
    "# 0.3265625, 01:46\n",
    "# 0.196875, 02:19\n",
    "# 0.1, 02:54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=25, shuffle=True))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=50, shuffle=True))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=100, shuffle=True))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=150, shuffle=True))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=200, shuffle=True))\n",
    "print(copy_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, token_max_len=250, shuffle=True))\n",
    "# 0.9296875\n",
    "# 0.6953125\n",
    "# 0.078125\n",
    "# 0.003125\n",
    "# 0.0\n",
    "# 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mamba 1.4B results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n",
      "100%|██████████| 20/20 [07:25<00:00, 22.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.346875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mamba_1_4b_tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\")\n",
    "mamba_1_4b_model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-1.4b-hf\")\n",
    "mamba_1_4b_model.to(device)\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=25))\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=50))\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=100))\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=150))\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=200))\n",
    "print(copy_task(batch_size=32, batches=20, model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=250))\n",
    "# 0.946875, 01:38\n",
    "# 0.8953125, 02:12\n",
    "# 0.7875, 03:55\n",
    "# 0.6296875, 04:09\n",
    "# 0.49375, 06:01\n",
    "# 0.346875, 07:25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=25, shuffle=True))\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=50, shuffle=True))\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=100, shuffle=True))\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=150, shuffle=True))\n",
    "print(copy_task(model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=200, shuffle=True))\n",
    "print(copy_task(batch_size=32, batches=20, model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, token_max_len=250, shuffle=True))\n",
    "# 0.9296875\n",
    "# 0.796875\n",
    "# 0.3125\n",
    "# 0.0390625\n",
    "# 0.0\n",
    "# 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mamba 2.8B results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_2_8b_tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-2.8b-hf\", padding_size='left')\n",
    "mamba_2_8b_model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-2.8b-hf\")\n",
    "mamba_2_8b_model.to(device)\n",
    "print(copy_task(model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=25))\n",
    "print(copy_task(model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=50))\n",
    "print(copy_task(batch_size=32, batches=20, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=100))\n",
    "print(copy_task(batch_size=16, batches=40, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=150))\n",
    "print(copy_task(batch_size=8, batches=80, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=200))\n",
    "print(copy_task(batch_size=8, batches=80, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=250))\n",
    "# 0.9484375, 00:55\n",
    "# 0.9296875, 02:02\n",
    "# 0.878125, 05:57\n",
    "# 0.7890625, 13:47\n",
    "# 0.6875, 24:58\n",
    "# 0.546875, 31:09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(copy_task(model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=25, shuffle=True))\n",
    "print(copy_task(model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=50, shuffle=True))\n",
    "print(copy_task(batch_size=32, batches=20, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=100, shuffle=True))\n",
    "print(copy_task(batch_size=16, batches=40, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=150, shuffle=True))\n",
    "print(copy_task(batch_size=8, batches=80, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=200, shuffle=True))\n",
    "print(copy_task(batch_size=8, batches=80, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer, token_max_len=250, shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mamba phone book lookup results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "name_phone_pairs = []\n",
    "with open('./phonebook.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line[-1] == ',':\n",
    "            line = line[:-1]\n",
    "        pair = ast.literal_eval(line)\n",
    "        name_phone_pairs.append((pair[0], pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We found the phone book experiment hard to reproduce as the author did not give the exact prompt in the paper. \n",
    "# In addition, the accuracy fluctutaed a lot with the prompt we used.\n",
    "\n",
    "import random\n",
    "def phone_book_task(batch_size=64, batches=10, book_size=20, model=None, tokenizer=None):\n",
    "    book = ''\n",
    "    success_lookups = 0\n",
    "    for i in range(book_size):\n",
    "        name = name_phone_pairs[i][0]\n",
    "        phone = name_phone_pairs[i][1]\n",
    "        book = book + name + ': ' + phone + '.\\n'\n",
    "    book += 'Extract the person\\'s phone number in the phonebook above. For example:\\nPerson: Liam\\nNumber: 436-725-2906\\nPerson: Olivia\\nNumber: 192-311-5790\\n\\n'\n",
    "    for _ in tqdm(range(batches)):\n",
    "        cur_batch = []\n",
    "        gold_num_tokens_batch = []\n",
    "        max_num_tokens = -1\n",
    "        for _ in range(batch_size):\n",
    "            query_pair_idx = random.randint(2, book_size)\n",
    "            query = book + 'Person: ' + name_phone_pairs[query_pair_idx][0] + '\\nNumber:'\n",
    "            gold_num_tokens = tokenizer(name_phone_pairs[query_pair_idx][1], return_tensors=\"pt\", padding=True).to(device)[\"input_ids\"]\n",
    "            max_num_tokens = max(max_num_tokens, gold_num_tokens.shape[1])\n",
    "            gold_num_tokens_batch.append(gold_num_tokens[0])\n",
    "            cur_batch.append(query)\n",
    "        input_ids = tokenizer(cur_batch, return_tensors=\"pt\", padding=True).to(device)[\"input_ids\"]\n",
    "        output_ids = model.generate(input_ids, max_new_tokens = max_num_tokens)\n",
    "        for count in range(batch_size):\n",
    "            true_number = tokenizer.decode(gold_num_tokens_batch[count])\n",
    "            output_answer = tokenizer.decode(output_ids[count])\n",
    "            if output_answer.count(true_number) > 1:\n",
    "                success_lookups += 1\n",
    "    return success_lookups / (batch_size * batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Mamba 370M results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_370m_tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-370m-hf\", padding_side='left')\n",
    "mamba_370m_model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-370m-hf\")\n",
    "mamba_370m_model.to(device)\n",
    "print(phone_book_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer))\n",
    "print(phone_book_task(model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, book_size=40))\n",
    "print(phone_book_task(batch_size=32, batches=20, model=mamba_370m_model, tokenizer=mamba_370m_tokenizer, book_size=80))\n",
    "# 0.6828125\n",
    "# 0.1953125\n",
    "# 0.053125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Mamba 1.4B results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.01s/it]\n",
      "100%|██████████| 20/20 [02:25<00:00,  7.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [04:12<00:00,  6.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [07:56<00:00, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mamba_1_4b_tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\", padding_side='left')\n",
    "mamba_1_4b_model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-1.4b-hf\")\n",
    "mamba_1_4b_model.to(device)\n",
    "print(phone_book_task(batch_size=32, batches=20, model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer))\n",
    "print(phone_book_task(batch_size=32, batches=20, model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, book_size=40))\n",
    "print(phone_book_task(batch_size=32, batches=20, model=mamba_1_4b_model, tokenizer=mamba_1_4b_tokenizer, book_size=80))\n",
    "# 0.625\n",
    "# 0.2390625\n",
    "# 0.0296875\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Mamba 2.8B results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:23<00:00, 27.84s/it]\n",
      "100%|██████████| 40/40 [04:43<00:00,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mamba_2_8b_tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-2.8b-hf\", padding_side='left')\n",
    "mamba_2_8b_model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-2.8b-hf\")\n",
    "mamba_2_8b_model.to(device)\n",
    "print(phone_book_task(batch_size=16, batches=40, model=mamba_2_8b_model, tokenizer=mamba_2_8b_tokenizer))\n",
    "# 0.9609375\n",
    "# 0.4546875\n",
    "# 0.0890625"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Aug 30 2023, 23:19:34) \n[GCC 7.3.1 20180712 (Red Hat 7.3.1-15)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
